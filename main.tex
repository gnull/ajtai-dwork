\documentclass[oneside, a4paper]{article}

\usepackage[T1,T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{url, hyperref}
\usepackage[shortlabels]{enumitem}
\usepackage{amssymb,amsthm,amsmath,mathtools}
\usepackage{listings}
\usepackage[many]{tcolorbox}
\usepackage{array}
\usepackage{float}

\usepackage{geometry}
 \geometry{
   a4paper,
   left=20mm,
   right=20mm,
 }

\usepackage{filecontents}

\theoremstyle{plain}
\newtheorem{theorem}{Теорема}
\newtheorem{lemma}[theorem]{Лемма}
\newtheorem{exce}{Упражнение}
\theoremstyle{definition}
\newtheorem{defn}{Определение}
\newtheorem{example}{Пример}
\theoremstyle{remark}
\newtheorem{remark}{Замечание}

% \renewcommand{\thesection}{}
% \renewcommand{\thesubsection}{}

% \newenvironment{definition}[1]{
% \begin{tcolorbox}[breakable,enhanced]
% \begin{defn}[#1]
% }{
% \end{defn}
% \end{tcolorbox}
% }

\newenvironment{definition}[1]{
\begin{defn}[#1]
}{
\end{defn}
}

\newenvironment{greybox}[1]{%
\begin{tcolorbox}[breakable,enhanced, adjusted title = #1]
}{%
\end{tcolorbox}
}

\DeclareMathOperator{\lcm}{LCM}
\DeclareMathOperator{\round}{Round}
\DeclareMathOperator{\Span}{span}
\DeclareMathOperator{\dist}{dist}

\newcommand\p{\ensuremath \mathbf p}
\newcommand\N{\ensuremath \mathcal N}
\newcommand\PP{\ensuremath \mathcal P}
\newcommand\LL{\ensuremath \mathcal L}
\newcommand\KK{\ensuremath \mathcal K}
\newcommand\R{\ensuremath \mathbb R}
\newcommand\Z{\ensuremath \mathbb Z}
\newcommand\HS{\ensuremath \operatorname{\mathcal H Samp}}
\newcommand\HH{\ensuremath \operatorname{\mathcal H}}

\DeclarePairedDelimiter\abs{\lvert}{\rvert}
\DeclarePairedDelimiter\norm{\lVert}{\rVert}
\DeclarePairedDelimiter\ang{\langle}{\rangle}

\DeclareRobustCommand{\divby}{%
  \mathrel{\vbox{\baselineskip.65ex\lineskiplimit0pt\hbox{.}\hbox{.}\hbox{.}}}%
}

\begin{document}

\title{Конспект статьи \\ \foreignlanguage{english}{<<The First and Fourth Public-Key Cryptosystems
with Worst-Case/Average-Case Equivalence>>  \cite{ajtaidwork}}}
\author{Олейников Иван \\ \url{ivan.oleynikov95@gmail.com}}
\date{\today}
\maketitle

Этот документ содержит конспект того, что я планировал рассказать
за одно занятие на семинаре по теоретической информатике в СПбГУ
\footnote{\url{https://groups.google.com/forum/\#!forum/spbsu-teorseminar}}.
Секции до <<\nameref{sec:decr}>> включительно самые простые, их я разобрал на
семинаре устно.
% поэтому они описаны не слишком подробно
Остальные секции, начиная с <<\nameref{sec:corr_proof}>>, содержат основную
часть статьи, её мне и не удалось разобрать их к началу семинара, поэтому после
семинара я написал этот конспект.

\tableofcontents

\section{Предварительные определения}

Напомним обозначения из статьи:
\begin{description}
  \item[$\N_m(0, \sigma^2)$~---] $m$-мерное нормальное распределение с дисперсией
  $\sigma^2$;

  \item[$\round_\alpha(x)$~---] округление вещественного числа $x$ вниз до
  ближайшего кратного $\alpha$. (Если $x$~--- вектор, то имеется ввиду
  округление каждой из его компонент.)
\end{description}

Мы будем описывать алгоритм так, будто он работает прямо с вещественными
числами. На самом деле он будет представлять все эти значения рациональными,
кратными $2^{-\p}$ и результаты всех операций и все значения, получаемые из
распределений на вещественных числах, будут округляться вниз до кратного
$2^{-\p}$.

\begin{definition}{$\HH_u$}
Для вектора $u \in \R^m$ определим $\HH_u$ как множество ортогональных $u$
гиперплоскостей, $i$-тая из которых содержит точки $v$, скалярное произведение
которых с $u$ равно $i$:
\[
\begin{aligned}
\HH_u = &\{H_i \mid i \in \Z \}, \\
&\text{where } H_i = \{v \in \R^m \mid \ang{v, u} = i\}.
\end{aligned}
\]
\end{definition}

Иногда мы будем нарушать нотацию о обозначать символом $\HH_u$ не множество
гиперплоскостей, а его объединение~--- $\bigcup_{H \in \HH_u} H$.

Легко заметить, что соседние гиперплоскости из $\HH_u$ находятся друг от друга
на расстоянии $1/\norm{u}$.

\begin{definition}{$\HS^{m, R}_{u_0 \dots u_l}$}
  \label{def:hsamp}
  $\HS^{m, R}_{u_0 \dots u_l}$~--- это распределение на векторах из $\R^m$, где
  $\{u_i\}$~--- это набор любых ортогональных векторов.
  
  Прежде, чем определить его, определим $\HS^{1, R}_{u}$~--- распределение на
  $\R$. Значение из него получается так: выберем $y' \gets \N(0, R^2)$ и округлим
  его вниз до ближайшего кратного $1/\norm u$, получим результат $\round_{1/\norm
  u}(y')$.
  
  Для получения значения из $\HS^{m, R}_{u_0 \dots u_l}$ получим по значению из
  распределений $\HS^{1,R}$ для каждого $u_i$:
  \[
  y_i \gets \HS^{1, R}_{u_i}, \quad \text{для каждого } i \in \{0 \dots l\}.
  \]
  Затем выберем ещё $m - (l + 1)$ значений из номального распределения:
  \[
  (y'_1, y'_2 \dots y'_{m - (l+1)}) \gets \N_{m - (l+1)}(0, R^2).
  \]
  И вернём в качестве результата значение
  \[
  \sum_{i=0}^l e_i y_i + \sum_{i=1}^{m - (l+1)} t_i y'_i,
  \]
  где значения $e_i = u_i / \norm{u_i}$~--- ортонормированный базис пространства
  $\Span \{u_i\}$, а $\{t_i\}$~--- любой ортонормальный базис $(n-1)$-мерного
  пространства $\Span \{u_i\}^\bot$.
\end{definition}

Легко заметить, что любое значение из распределения $\HS^{1,R}_{u_0 \dots u_l}$
будет лежать в пересечении семейств гиперплоскостей $\bigcap_i \HH_{u_i}$.

\section{Описание криптосистемы}

Криптосистема будет параметризоваться несколькими значениями: параметром
надёжности~--- $n$ и длиной шифруемого сообщения в битах~--- $(l+1)$.
Пользователь криптосистемы может выбрать их какими угодно, но от них будут
зависеть свойства криптосистемы, такие как <<надёжность>>~--- вероятность
успешного взлома противником и время работы алгоритмов криптосистемы. Мы часто
будем работать в $\R^{n+l}$, поэтому для краткости записи обозначим $m = n +
l$. Ещё при задании криптосистемы будем пользоваться функциями $\rho(n)$ и
$R(n)$, точные значения для которых мы выберем в самом конце при доказательстве
надёжности.

Наша криптосистема будет шифровать сообщения из $l+1$ бит~--- $b_0, b_1 \dots
b_l \in \{0,1\}$. Результатом шифрования сообщения будет вектор $x \in \R^m$
(как мы увидим дальше, этот вектор всегда будет лежать внутри параллелепипеда
$\PP$, определённого ниже).

Секретный ключ нашей криптосистемы будет состоять из $u_0, u_1 \dots u_l \in
\R^m$~--- набора из $l+1$ ортогональных векторов. Публичный ключ будет состоять
из тройки $(\PP, V, D)$ наборов векторов в $\R^m$:

\begin{description}
  \item[$\PP = \{p_1 \dots p_m\}$~---] эти вектора задают базис решётки, по
  модулю которой будет вычисляться шифруемое сообщение. То есть результат
  шифрования будет лежать в $\R^m/\LL(\PP)$. (Мы будем нарушать нотацию и
  обозначать символом $\PP$ как множество векторов, задающих базис этой решётки,
  так и фундаментальный параллелепипед этой решётки $\PP = \left \{\sum_i a_i
  p_i \mid a_1, a_2 \dots a_m \in [0, 1) \right\}$.)

  \item[$V = \{v_0 \dots v_l\}$~---] эти вектора будут использоваться для
  кодирования сообщения (их не случайно ровно столько же, сколько бит в
  сообщении~--- для кодирования сообщения мы будем вычислять сумму подмножества
  $V$, задаваемого единичными битами сообщения).

  \item[$D = \{d_1 \dots d_{m'}\}$~---] эти вектора используются для наложения
  <<шума>> на шифруемое сообщение, чтобы противнику было «труднее» восстановить
  сообщение. $m'(n)$~--- это функция от $n$, которую мы выберем позже при
  доказательстве корректности криптосистемы (можно представлять себе, что чем
  больше $m'$, тем более <<сильный>> шум накладывается на сообщение).
\end{description}

Давайте введём два дополнительных обозначения для уже знакомых нам
распределений:
\begin{itemize}
  \item $\xi_R = \HS^{m, R}_{u_0 \dots u_l}$, где в качестве набора векторов
  $\{u_i\}$ зафиксирован секретный ключ криптосистемы, а в качестве $m$
  фиксировано значение $m = n + l$. То есть $\xi_R$ имеет своим параметром
  только $R$.

  \item $\pi_\rho = \N_m(0, \rho^2)$, параметрированное только $\rho$.
\end{itemize}

\begin{remark}[Разложение $\xi_R + \pi_\rho$ на $AZ + T + Q$]
\label{rem:xi_R}
По определению $\HS^{m,R}_{u_0 \dots u_l}$, значение из $\xi_R$ состоит из двух
слагаемых:
\[
  \sum_{i=0}^l e_i y_i + \sum_{i=1}^{m - (l+1)} t_i y'_i.
\]
Перепишем первое из них как
\[
  \sum_{i=0}^l z_i a_i,
    \text{ where } z_i = e_i / \norm{u_i} = u_i / \norm{u_i}^2, a_i = y_i \norm{u_i}.
\]
Видно, что $a_i \in \Z$, ведь $y_i$ кратны $1/\norm{u_i}$ (подробнее смотрите в
определении \nameref{def:hsamp}).

Вектор-строку $v$ из распределения $\HS^{m,R}_{u_0 \dots u_l}$ можно получить
таким образом:
\[
  v =
  \underbrace{
    \begin{bmatrix}
    a_0 & \cdots & a_l
    \end{bmatrix}
  }_{A \in \Z^{l+1}}
  \times
  \underbrace{
    \begin{bmatrix}
    z_0 \\ \vdots \\ z_l
    \end{bmatrix}
  }_{Z \in \R^{(l+1) \times m}}
  +
  \underbrace{
    \sum_{i=1}^{m - (l+1)} t_i y'_i
  }_{T \in \R^m},
\]
причём $i$-тая компонента случайной целочисленной матрицы $A$ задаёт номер
гиперплоскости из семейства $\HH_{u_i}$, в которой будет лежать $v$, а случайный
вектор-строка $T$ задаёт какое-то смещение внутри пересечения таких
гиперплоскостей.

Если теперь обозначить символом $Q$ случайную величину из $\pi_\rho$, то
распределение $\xi_R + \pi_\rho$ можно представить как $AZ + T + Q$.

Более того, если мы получаем $k$ значений из распределения $\xi_R + \pi_\rho$:
\[
\begin{aligned}
  v_1 &\gets \xi_R + \pi_\rho \\
  v_2 &\gets \xi_R + \pi_\rho \\
      &\dots \\
  v_k &\gets \xi_R + \pi_\rho,
\end{aligned}
\] то распределение на $\{v_i\}$ можно выразить аналогичным образом:
\[
  \begin{bmatrix}
    v_1 \\ \vdots \\ v_k
  \end{bmatrix}
  = AZ + T + Q,
\]
только теперь матрицы будут другой размерности~---
$A \in \Z^{k \times (l+1)}$ и $T, Q \in \R^{k \times m}$.
\end{remark}

Как мы увидим в следующей секции, все вектора из множеств $\PP$, $V$ и $D$
публичного ключа будут выбираться из распределения $\xi_R + \pi_\rho$ (с
некоторыми дополнительными требованиями). Это значит, что они все будут «близки»
к пересечению семейств гиперплоскостей $\bigcap_i \HH_{u_i}$ и будут
отклоняться от него на ошибку из $\pi_\rho$.

\subsection{Генерация ключей}
\label{sec:gen}
В этой секции мы опишем вероятностный алгоритм генерации ключей $G$, который
будет принимать на вход параметр безопасности $n$ и выдавать пару из публичного
и секретного ключей~---
\[
(
\underbrace{\{u_i\}}_{\substack{\text{секретный} \\ \text{ключ}}},
\underbrace{(\PP, V, D)}_{\substack{\text{публичный} \\ \text{ключ}}}
) \gets G(1^n).
\]

\emph{Выбор секретного ключа $\{u_i\}$.} Независимо выберем: (a) $\{e_i\}$~---
вектора единичной длины, задающие направления для $\{u_i\}$; (b) их длины
$\norm{u_i} \in \R$. После этого можно будет положить $u_i = e_i \norm{u_i}$.
\begin{enumerate}[(a)]
  \item Будем выбирать случайные значения для $\{e_i\}$ одно за другим~---
  значение для $e_i$ будем выбирать после того, как значения для $e_0, e_1
  \dots e_{i-1}$ уже выбраны. Выберем $e_i$ из равномерного распределения на
  сфере радиуса $1$ в пространстве $\Span \{e_0, e_1 \dots e_{i-1}\}^\bot$,
  ортогональном порождённому выбранными ранее векторами. ($e_0$ выбирается
  из оригинального пространства $\R^m$, $e_1$~--- из его $(m-1)$-мерного
  подпространства и так далее.)

  По выбору этих векторов ясно, что они всегда будут ортогональны.
  Распределение, из которого мы выбираем $e_i$ зависит от предыдущих векторов
  $e_0 \dots e_{i-1}$. Но легко заметить, что несмотря на это итоговое
  распределение всего множества векторов $\{u_i\}$ не изменится, если выбирать
  их в другом порядке, --- оно симметрично относительно перестановок $\{u_i\}$.

  \item Длины $\{u_i\}$ выберем независимо друг от друга таким образом: выберем
  $y$ из $\mathcal B^{(m)}(0,1)$~--- равномерного распределения на шаре радиуса
  $1$ с центром в начале координат в $n$-мерном пространстве $\R^n$; положим
  очередное значение $\norm{u_i} := \norm{y}$. (Эту процедуру проделаем для
  каждого $i$.)
\end{enumerate}

\emph{Выбор публичного ключа.} Секретный ключ мы уже выбрали. Наш выбор
публичного ключа будет зависеть от него. Все вектора из $V$, $D$ и $\PP$ выберем
независимо друг от друга из распределения $\xi_R + \pi_\rho$. Напомним, что
определение $\xi_R = \HS^{m, R}_{u_0 \dots u_l}$ зависит от секретного ключа
$\{u_i\}$.

Но какие попало значения из $\xi_R + \pi_\rho$ в качестве векторов публичного
ключа не подойдут нам для шифрования. Чтобы шифрование и дешифрование работало,
нам нужно потребовать от векторов выполнения нескольких дополнительных свойств:
\begin{description}
  \item[$V$~---] При разложении $V$ на $AZ + Q + T$ как это было описано в
  определении $\xi_R + \pi_\rho$, целочисленная матрица $A$ должна быть обратима
  по ${\mod 2}$.

  \item[$\PP$~---] Ширина параллелепипеда должна быть не менее $\KK(n)/(n+l)^2$,
  а число рациональных точек в нём~--- $\PP \cap 2^{-\p}\Z^{n+l}$ должно быть
  нечётным. (Ещё нам нужно, чтобы $\{p_i\}$ были линейно независимы, но это
  свойство нарушается вероятностью, экспоненциально убывающей с увеличением $n$,
  поэтому даже не будем останавливаться на нём.)

  \begin{definition}{Ширина параллелепипеда}
  Шириной параллелепипеда $\PP$ будем называть максимальное по его вершинам
  расстояние от вершины параллелепипеда до пространства порождённого остальными
  вершинами:
  \[
  w(\PP) = \max_i \dist(p_i, \Span \{ p_j \mid j \neq i\}).
  \]
  \end{definition}

  Требование на число точек гарантирует нам, что все подгруппы $2^{-\p}\Z / \PP$
  имеют нечётный порядок. Поэтому функция $(v \mapsto 2v)$ будет биекцией на
  этом множестве. Смысл требования к ширине параллелепипеда мы объясним в секции
  <<\nameref{sec:corr_proof}>>.

  \item[$\pi_\rho$~---] Все компоненты векторов из распределения $\pi_\rho$,
  участвующих как слагаемые в векторах из публичного ключа, не должны превышать
  по модулю $\rho \log^2 n$. То есть $\norm{\pi_\rho}_\infty \leq \rho \log^2
  n$.

  Это требование гарантирует нам, что после наложения <<шума>> $\pi_\rho$ на
  вектор $\xi_R$, лежащий в пересечении гиперплоскостей $\{\HH_{u_i}\}$, вектор
  сместится не слишком сильно и мы сможем узнать, на пересечении каких именно
  гиперплоскостей лежал $\xi_R$, округлив $\xi_R + \pi_\rho$ определённым
  образом.
\end{description}

Следующие три леммы, приведённые без доказательства, показывают, что эти
требования выполняются с константной вероятностью для случайных векторов из
$\xi_R + \pi_\rho$. Если не повезло и какое-то требование не выполнилось, то
мы можем генерировать вектора заново раз за разом, пока не получится. При
повторении генерации несколько раз, вероятность того, что каждый из этих раз
будет неудачным, убывает экспоненциально с числом повторений. Поэтому число
повторений в среднем будет константным.

\begin{lemma}[Лемма 8.1 в оригинале]
Вероятность того, что случайная матрица $A \in \{0,1\}^{n \times n}$, каждый
элемент которой выбран равномерно из $\{0,1\}$, будет обратима, ограничивается
снизу константой.
\end{lemma}

Случайная матрица $A$, описанная в замечании \ref{rem:xi_R}, состоит из целых
чисел. Каждый её элемент независимо берётся из какого-то напределения на $\Z$
(для каждого элемента распределение своё), но легко заметить, что чётные числа
выпадают в этом распределении с той же вероятностью, что и нечётные. Поэтому
лемма выше применима к той матрице $A$ и она будет обратима по модулю $2$ с
константной вероятностью.

\begin{lemma}[Не формулируется в оригинале]
\[
  \Pr_{q \gets \N_m(0, \rho)} \left[ \norm{q}_\infty \geq \rho \log^2 n \right]
  > (1 - \frac{1}{\log^4 n})^m
\]
\end{lemma}

Эта лемма очевидна из неравенства Чебышёва. Она гарантирует, что вероятность
выполнения требования на $\pi_\rho$ ограничивается снизу ненулевой константой.

Вероятность выполнения требования на ширину параллелепипеда $\PP$ мы оценим в
секции <<\nameref{sec:corr_proof}>>.

\subsection{Шифрование}
\label{sec:encr}
В этой секции мы опишем процесс шифрования. Шифрующий алгоритм принимает на вход
сообщение $b_0 b_1 \dots b_l$ из $l+1$ бит, а также публичный ключ $(\PP, V, D)$
и должен выдать на выход шифротекст сообщения $x \in \R^m$:
\[
  \underbrace{x}_{\substack{\text{код} \\ \text{сообщения}}}
  \gets
  E(
    \underbrace{\PP, V, D}_{\substack{\text{публичный} \\ \text{ключ}}}
    ,
    \underbrace{b_0 b_1 \dots b_l}_{\text{сообщение}}
  ).
\]

Выберем $m'$ независимых случайных бит: $\delta_i \gets \{0,1\}$ для $i \in \{0
\dots m'\}$. Положим шифротекст сообщения $x$ равным
\[
  x =
  \underbrace{\sum_{i = 0}^l b_i v_i}_
  {\substack{\text{слагаемое,} \\ \text{кодирующее} \\ \text{сообщение}}}
  +
  \underbrace{\sum_{i = 1}^{m'} 2 \delta_i d_i}_
  {\text{<<шум>>}}
  \mod \PP.
\]

Первое слагаемое в этой сумме~--- это код сообщения, по нему можно восстановить
сообщение, даже не имея секретного ключа, что демонстрируется упражнением ниже.
А второе слагаемое~--- это <<шум>>, который накладывается, чтобы не имеющий
секретного ключа не мог восстановить данные, а имеющий секретный ключ мог это
сделать, избавившись от шума.

\begin{remark}
По заданным значениям $\sum_{i = 0}^l b_i v_i$ и $V$ можно определить $b_0 \dots
b_l$ решением системы линейных уравнений.
\end{remark}

Это можно сделать, даже если сумма дана по модулю $\PP$. (Для $V$ и $\PP$,
конечно же, должны выполняться требования на публичный ключ из секции
<<\nameref{sec:gen}>>.) Мы докажем это в секции <<\nameref{sec:corr_proof}>>.

\subsection{Дешифрование}
\label{sec:decr}
В этой секции мы опием процесс дешифрования. Дешифрующий алгоритм принимает оба
ключа вместе с кодом сообщения и должен восстановить по ним исходное сообщение:
\[
  \underbrace{b_0 b_1 \dots b_l}_{\text{сообщение}}
  \gets D(
  \underbrace{\{u_i\}}_{\substack{\text{секретный} \\ \text{ключ}}}
  ,
  \underbrace{\PP, V, D}_{\substack{\text{публичный} \\ \text{ключ}}}
  ,
  \underbrace{x}_{\substack{\text{код} \\ \text{сообщения}}}
  )
\]

Напомним, как был получен $x$ алгоритмом из предыдущей секции:
\[
  x =
  \sum_{i = 0}^l b_i v_i
  +
  \sum_{i = 1}^{m'} 2 \delta_i d_i
  \mod \PP.
\]

Напомним, что вектора из $V$ и $D$ получены из распределения $\xi_R + \pi_\rho$
(с некоторыми дополнительными требованиями). Если записать эти наборы векторов в
виде матриц, строками которых будут вектора:
\[
\begin{aligned}
  V = \begin{bmatrix}
    v_0 \\
    v_1 \\
    \vdots \\
    v_l
  \end{bmatrix}
  &
  \quad\quad
  &
  D = \begin{bmatrix}
    d_1 \\
    d_2 \\
    \vdots \\
    d_{m'}
  \end{bmatrix}
\end{aligned},
\]
то их можно записать в таком виде (как это было сделано в определении $\xi_R +
\pi_\rho$):
\[
\begin{aligned}
  V = A_V Z_V + Q_V + T_V &
  \quad\quad &
  D = A_D Z_D + Q_D + T_D. &
\end{aligned}
\]

Для этого сначала выразим все вектора (включая $x, V, D, \PP$), с которыми
мы работаем, в базисе $\{ z_0 \dots z_l \} \cup \{t_1 \dots t_{n-1}\}$, где
$\{t_i\}$~--- это какой-нибудь ортонормированный базис пространства $\Span
\{z_i\}^\bot$. Затем обнулим соответствующие $\{t_1 \dots t_{n-1}\}$ компоненты
$x$ (другими словами, спроецируем $x$ на $\Span \{z_i\}$).

\subsection{Доказательство корректности}
\label{sec:corr_proof}
Докажем, что зашифрованные такой криптосистемой данные будут корректно
восстановлены с пренебрежимо малой вероятностью ошибки.

\begin{lemma}[Лемма 8.2 в оригинале]
Если выбрать $p_i \gets \N(0, \sigma)$ для всех $i \in \{1 \dots m\}$, то
вероятность
\[
  \Pr \left[
  \substack{
  \displaystyle
  \text{$\exists$ такое $i$, что} \\
  \displaystyle
  \dist(p_i, \Span \{p_i \mid i \neq j\}) \leq \frac{2}{(n+l) e^{\sqrt{2/\pi}}}\
  }
  \right]
  \leq \sqrt{\frac 2 \pi} < 1.
\]
\end{lemma}


\section{Доказательство надёжности}
Сведём решение \foreignlanguage{english}{worst-case} задачи
\foreignlanguage{english}{Unique Shortest Vector} к взлому определённой нами
криптосистемы.

\bibliographystyle{plain}
\foreignlanguage{english}{
  \bibliography{main}
}
\begin{filecontents}{main.bib}
@article{ajtaidwork,
  author    = {Mikl{\'{o}}s Ajtai and
               Cynthia Dwork},
  title     = {The First and Fourth Public-Key Cryptosystems with Worst-Case/Average-Case
               Equivalence. \url{http://eccc.hpi-web.de/eccc-reports/2007/TR07-097/index.html}},
  journal   = {Electronic Colloquium on Computational Complexity {(ECCC)}},
  volume    = {14},
  number    = {097},
  year      = {2007},
  url       = {http://eccc.hpi-web.de/eccc-reports/2007/TR07-097/index.html},
  timestamp = {Tue, 14 Aug 2018 17:08:03 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/eccc/AjtaiD07},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
\end{filecontents}

\end{document}
